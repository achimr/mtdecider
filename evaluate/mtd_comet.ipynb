{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "running_in_colab = 'google.colab' in str(get_ipython())\n",
    "homedir = \"\"\n",
    "if running_in_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    homedir = \"/content/drive/MyDrive\"\n",
    "else:\n",
    "    homedir = os.getenv('HOME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "if running_in_colab:\n",
    "    !pip3 install nbdev\n",
    "    !pip3 install mteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mteval.dataset import *\n",
    "from mteval.comet import *\n",
    "from mteval.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "mtengines_selection = widgets.SelectMultiple(\n",
    "    options=['aws','deepl','google', 'microsoft','modernmt'],\n",
    "    value=['aws'],\n",
    "    description='MT Engines:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(mtengines_selection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mtengines_selection.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "base_path = homedir+\"/mtd_data/\"\n",
    "dataset_fname = \"datasets.csv\"\n",
    "metrics_fname = \"comet.csv\"\n",
    "normalize_quotes = False\n",
    "\n",
    "comet_scorer = cometscoring()\n",
    "with open(base_path+dataset_fname,'r') as datasets_fh:\n",
    "    set_reader = csv.reader(datasets_fh)\n",
    "    for (source_language_code,target_language_code,test_set_name,test_date,domain) in set_reader:\n",
    "        for mtengine in mtengines_selection.value:\n",
    "            source_lines = []\n",
    "            reference_lines = []\n",
    "            source_lines, reference_lines = download_read_set(base_path,source_language_code,target_language_code,test_set_name)\n",
    "            target_lines = []\n",
    "            try:\n",
    "                target_lines = get_translated_test_set(base_path,source_language_code,target_language_code,mtengine,test_set_name,test_date,domain)\n",
    "            except FileNotFoundError:\n",
    "                print(\"Translated file not found\",file=sys.stderr)\n",
    "                continue\n",
    "            if normalize_quotes == True:\n",
    "                utils = util()\n",
    "                source_lines = [utils.normalize_quotes(source_line) for source_line in source_lines]\n",
    "                reference_lines = [utils.normalize_quotes(reference_line) for reference_line in reference_lines]\n",
    "                target_lines = [utils.normalize_quotes(target_line) for target_line in target_lines]\n",
    "            print(\"COMET benchmarking {}-{} Testset: {} Date: {} MT engine: {} Domain: {}\".format(source_language_code,target_language_code,test_set_name,test_date,mtengine,domain))\n",
    "            comet_scorer.measure_record_comet(source_lines,target_lines,reference_lines,source_language_code,target_language_code,test_set_name,test_date,mtengine,base_path,metrics_fname,domain)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
